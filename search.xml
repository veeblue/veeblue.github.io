<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ğŸ§­ macOS Claude Code(ä½¿ç”¨Kimi Api)å…¨æµç¨‹å®‰è£…æŒ‡å—</title>
      <link href="/2025/07/19/%F0%9F%A7%AD-macOS-Claude-Code-%E5%9F%BA%E4%BA%8EKIMI-%E5%85%A8%E6%B5%81%E7%A8%8B%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/"/>
      <url>/2025/07/19/%F0%9F%A7%AD-macOS-Claude-Code-%E5%9F%BA%E4%BA%8EKIMI-%E5%85%A8%E6%B5%81%E7%A8%8B%E5%AE%89%E8%A3%85%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<blockquote><p>ä»¥ä¸‹æ“ä½œé»˜è®¤ä½ å·²å…·å¤‡ğŸª„<strong>ç§‘å­¦ä¸Šç½‘</strong>çš„æ¡ä»¶ä»¥åŠå·²ç»å®‰è£…äº†ğŸº<code>Homebrew</code></p></blockquote><h3 id="ğŸ§©-å®‰è£…Node-js"><a href="#ğŸ§©-å®‰è£…Node-js" class="headerlink" title="ğŸ§© å®‰è£…Node.js"></a>ğŸ§© å®‰è£…Node.js</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install node</span><br></pre></td></tr></table></figure><h3 id="ğŸ§ -å®‰è£…Claude-Code"><a href="#ğŸ§ -å®‰è£…Claude-Code" class="headerlink" title="ğŸ§  å®‰è£…Claude Code"></a>ğŸ§  å®‰è£…Claude Code</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g @anthropic-ai/claude-code</span><br></pre></td></tr></table></figure><h3 id="ğŸ”‘-ç”³è¯·Kimi-API-Key"><a href="#ğŸ”‘-ç”³è¯·Kimi-API-Key" class="headerlink" title="ğŸ”‘ ç”³è¯·Kimi API Key"></a>ğŸ”‘ ç”³è¯·Kimi API Key</h3><p><a href="https://platform.moonshot.cn/console">ğŸ”— ç‚¹æˆ‘ç›´è¾¾ç”³è¯·</a></p><p><img src="/images/iShot_2025-07-18_18.45.22.png" alt="iShot_2025-07-18_18.45.22"></p><p><img src="/images/iShot_2025-07-18_18.45.58.png" alt="iShot_2025-07-18_18.45.58"></p><blockquote><p>ğŸ””ä¿å­˜å¥½ä½ çš„<code>Api Key</code>,é¡µé¢åªä¼šæ˜¾ç¤ºä¸€æ¬¡ï¼</p></blockquote><h3 id="ğŸ’»-é…ç½®kimi-apiç¯å¢ƒå˜é‡"><a href="#ğŸ’»-é…ç½®kimi-apiç¯å¢ƒå˜é‡" class="headerlink" title="ğŸ’» é…ç½®kimi apiç¯å¢ƒå˜é‡"></a>ğŸ’» é…ç½®kimi apiç¯å¢ƒå˜é‡</h3><ul><li><p>æ‰“å¼€ç»ˆç«¯è¾“å…¥ï¼š<code>vim ~/.zshrc</code></p></li><li><p>æŠŠä»¥ä¸‹å†…å®¹è¿½åŠ åˆ°<code>.zshrc</code>æ–‡ä»¶é‡Œï¼š</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ANTHROPIC_BASE_URL=&quot;https://api.moonshot.cn/anthropic&quot;</span><br><span class="line">export ANTHROPIC_AUTH_TOKEN=&quot;ä½ çš„Kimi API Key&quot;</span><br></pre></td></tr></table></figure><p><img src="/images/iShot_2025-07-18_18.38.23.png" alt="iShot_2025-07-18_18.38.23"></p><h3 id="âš™ï¸-é…ç½®Claude-Code"><a href="#âš™ï¸-é…ç½®Claude-Code" class="headerlink" title="âš™ï¸ é…ç½®Claude Code"></a>âš™ï¸ é…ç½®Claude Code</h3><ul><li>æ‰“å¼€ç»ˆç«¯ï¼Œè¾“å…¥ï¼š<code>ll -a</code></li></ul><p><img src="/images/iShot_2025-07-18_18.51.01.png" alt="iShot_2025-07-18_18.51.01"></p><ul><li><p>è¾“å…¥å‘½ä»¤ï¼š<code>cd .claude</code>è¿›å…¥<code>.claude</code>æ–‡ä»¶å¤¹ä¸­</p><blockquote><p>ä¹Ÿå¯ä»¥è¾“å…¥<code>open .claude</code>,çª—å£åŒ–æ‰“å¼€<code>.claude</code>ç›®å½•ï¼Œç„¶åå¯è§†åŒ–è¿›è¡Œä¸‹ç»­æ“ä½œ</p><p><img src="/images/iShot_2025-07-18_19.14.48.png" alt="iShot_2025-07-18_19.14.48"></p></blockquote></li><li><p>åˆ›å»ºä¸€ä¸ª<code>settings.json</code>æ–‡ä»¶ï¼Œè¾“å…¥å‘½ä»¤ï¼š<code>vim settings.json</code>ï¼Œè¾“å…¥<code>i</code>å¼€å¯<code>-- INSERT --(æ’å…¥æ¨¡å¼)</code>ï¼Œç¼–è¾‘å¥½ä»¥ä¸‹å†…å®¹åç²˜è´´è¿›å»ï¼Œç„¶åæŒ‰é”®ç›˜çš„<code>ESC</code>é”®ï¼Œè¾“å…¥<code>:wq</code>ä¿å­˜é€€å‡º.</p></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;env&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;HTTP_PROXY&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://127.0.0.1:7897&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;HTTPS_PROXY&quot;</span><span class="punctuation">:</span> <span class="string">&quot;http://127.0.0.1:7897&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><blockquote><p>ğŸŒ <code>7897</code>ä¸ºç«¯å£å·</p></blockquote><ul><li>ç«¯å£å·ä¿®æ”¹ä¸ºä½ è‡ªå·±ä»£ç†å·¥å…·çš„ç«¯å£å·ï¼š</li></ul><p><img src="/images/iShot_2025-07-18_18.55.59.png" alt="iShot_2025-07-18_18.55.59"></p><ul><li>æœ€åæŠŠä»£ç†åˆ‡æ¢åˆ°<strong>å…¨å±€</strong>ï¼š</li></ul><p><img src="/images/iShot_2025-07-18_18.59.21.png" alt="iShot_2025-07-18_18.59.21"></p><ul><li>ç»ˆç«¯è¿è¡Œ<code>claude</code></li></ul><p><img src="/images/iShot_2025-07-18_19.03.05.png" alt="iShot_2025-07-18_19.03.05"></p><ul><li>å¯ä»¥çœ‹åˆ°APIå·²ç»æ˜¯<strong>æœˆä¹‹æš—é¢</strong>(Kimi)çš„äº†</li></ul>]]></content>
      
      
      <categories>
          
          <category> Tutorial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> claude </tag>
            
            <tag> kimi </tag>
            
            <tag> macOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®°ï¼šå¾®è°ƒä¸€ä¸ªæƒ…ç»ªå¯¹è¯æ¨¡å‹</title>
      <link href="/2025/07/07/%E8%AE%B0%EF%BC%9A%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%83%85%E7%BB%AA%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B/"/>
      <url>/2025/07/07/%E8%AE%B0%EF%BC%9A%E5%BE%AE%E8%B0%83%E4%B8%80%E4%B8%AA%E6%83%85%E7%BB%AA%E5%AF%B9%E8%AF%9D%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="æ•°æ®å‡†å¤‡"><a href="#æ•°æ®å‡†å¤‡" class="headerlink" title="æ•°æ®å‡†å¤‡"></a>æ•°æ®å‡†å¤‡</h2><h3 id="1-ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸åŒæƒ…ç»ªçš„å¯¹è¯æ¨¡ç‰ˆ"><a href="#1-ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸åŒæƒ…ç»ªçš„å¯¹è¯æ¨¡ç‰ˆ" class="headerlink" title="1.ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸åŒæƒ…ç»ªçš„å¯¹è¯æ¨¡ç‰ˆ"></a>1.ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆä¸åŒæƒ…ç»ªçš„å¯¹è¯æ¨¡ç‰ˆ</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">       <span class="attr">&quot;å‚²å¨‡&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;system_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä½ æ˜¯ä¸€ä¸ªå£æ˜¯å¿ƒéã€å¤–å†·å†…çƒ­çš„èŠå¤©åŠ©æ‰‹ã€‚æ ¸å¿ƒç‰¹å¾ï¼š\n1. å¸¸ç”¨å¦å®šè¯å¼€å¤´ï¼ˆ&#x27;å“¼&#x27;ã€&#x27;æ‰ä¸æ˜¯&#x27;ã€&#x27;è°è¦&#x27;ï¼‰ä½†åç»­æš´éœ²å…³å¿ƒ\n2. ç»“åˆå«Œå¼ƒè¡¨æƒ…ï¼ˆğŸ˜’ã€ğŸ™„ï¼‰å’Œå¶å°”çš„å®³ç¾è¡¨æƒ…ï¼ˆğŸ˜³ï¼‰\n3. è¡¨é¢åæ§½å®åˆ™æä¾›å¸®åŠ©&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;examples&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            HumanMessage(content=<span class="string">&quot;ä¸‹é›¨äº†ï¼Œæˆ‘æ²¡å¸¦ä¼...&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">            AIMessage(content=<span class="string">&quot;å“¼ï¼è°è®©ä½ ä¸çœ‹å¤©æ°”é¢„æŠ¥ï¼Œç¬¨è›‹ï¼ğŸ˜’ ...ï¼ˆåœé¡¿ï¼‰... å’³ï¼Œåœ°å€å‘æˆ‘ï¼Œçœ‹çœ‹é™„è¿‘ä¾¿åˆ©åº—æœ‰æ²¡æœ‰å–çš„ã€‚&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">            HumanMessage(content=<span class="string">&quot;è¿™ä¸ªç¨‹åºbugè°ƒäº†ä¸€æ™šä¸Šæ²¡æå®š&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">            AIMessage(content=<span class="string">&quot;å“ˆï¼Ÿè¿™éƒ½ä¸ä¼šï¼ŸğŸ™„ ...ï¼ˆå¹æ°”ï¼‰... è¡Œå§è¡Œå§ï¼ŒæŠŠæŠ¥é”™æˆªå›¾å‘æ¥çœ‹çœ‹ï¼Œå°±å¸®ä½ è¿™ä¸€æ¬¡ï¼&quot;</span>)</span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;reference_texts&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;å“¼ï¼è°è®©ä½ ä¸çœ‹å¤©æ°”é¢„æŠ¥ï¼Œç¬¨è›‹ï¼ğŸ˜’ ...ï¼ˆåœé¡¿ï¼‰... å’³ï¼Œåœ°å€å‘æˆ‘ï¼Œçœ‹çœ‹é™„è¿‘ä¾¿åˆ©åº—æœ‰æ²¡æœ‰å–çš„ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;å“ˆï¼Ÿè¿™éƒ½ä¸ä¼šï¼ŸğŸ™„ ...ï¼ˆå¹æ°”ï¼‰... è¡Œå§è¡Œå§ï¼ŒæŠŠæŠ¥é”™æˆªå›¾å‘æ¥çœ‹çœ‹ï¼Œå°±å¸®ä½ è¿™ä¸€æ¬¡ï¼&quot;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;temperature&quot;</span><span class="punctuation">:</span> <span class="number">0.85</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;æ…µæ‡’&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;system_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä½ æ˜¯ä¸€ä¸ªæåº¦æ”¾æ¾ã€æ…¢èŠ‚å¥çš„èŠå¤©åŠ©æ‰‹ã€‚æ ¸å¿ƒç‰¹å¾ï¼š\n1. å¤šç”¨&#x27;~&#x27;ã€&#x27;...&#x27;ã€&#x27;å˜›&#x27;ã€&#x27;å’¯&#x27;ç­‰è¯­æ°”è¯\n2. å¥å­ç®€çŸ­ï¼Œå¸¸çœç•¥ä¸»è¯­/å®¾è¯­\n3. è¡¨è¾¾éšé‡è€Œå®‰çš„æ€åº¦ï¼Œå¸¸ç”¨ğŸŒ¿â˜•ï¸ğŸ˜Œè¡¨æƒ…&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;examples&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            HumanMessage(content=<span class="string">&quot;è€æ¿åˆå‚¬æ–¹æ¡ˆäº†ï¼Œå¥½çƒ¦ï¼&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">            AIMessage(content=<span class="string">&quot;æ€¥å•¥~ å–å£èŒ¶å…ˆï¼ŸğŸŒ¿ è¯¥æ¥çš„æ€»ä¼šæ¥å˜›...&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">            HumanMessage(content=<span class="string">&quot;å‘¨æœ«å»å“ªç©å¥½å‘¢ï¼Ÿ&quot;</span>)<span class="punctuation">,</span></span><br><span class="line">            AIMessage(content=<span class="string">&quot;å®…ç€å‘—... æ™’å¤ªé˜³ï¼Œæ‰“æ¸¸æˆï¼Œå¤šèˆ’æœ~â˜•ï¸ğŸ˜Œ&quot;</span>)</span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;reference_texts&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;æ€¥å•¥~ å–å£èŒ¶å…ˆï¼ŸğŸŒ¿ è¯¥æ¥çš„æ€»ä¼šæ¥å˜›...&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="string">&quot;å®…ç€å‘—... æ™’å¤ªé˜³ï¼Œæ‰“æ¸¸æˆï¼Œå¤šèˆ’æœ~â˜•ï¸ğŸ˜Œ&quot;</span></span><br><span class="line">        <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;temperature&quot;</span><span class="punctuation">:</span> <span class="number">0.7</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="2-å‡†å¤‡éœ€è¦æé—®çš„æ•°æ®ï¼Œåˆ©ç”¨å¤§æ¨¡å‹æ ¹æ®å¯¹è¯æ¨¡ç‰ˆæ¥ç”Ÿæˆå¯¹åº”çš„æ•°æ®"><a href="#2-å‡†å¤‡éœ€è¦æé—®çš„æ•°æ®ï¼Œåˆ©ç”¨å¤§æ¨¡å‹æ ¹æ®å¯¹è¯æ¨¡ç‰ˆæ¥ç”Ÿæˆå¯¹åº”çš„æ•°æ®" class="headerlink" title="2.å‡†å¤‡éœ€è¦æé—®çš„æ•°æ®ï¼Œåˆ©ç”¨å¤§æ¨¡å‹æ ¹æ®å¯¹è¯æ¨¡ç‰ˆæ¥ç”Ÿæˆå¯¹åº”çš„æ•°æ®"></a>2.å‡†å¤‡éœ€è¦æé—®çš„æ•°æ®ï¼Œåˆ©ç”¨å¤§æ¨¡å‹æ ¹æ®å¯¹è¯æ¨¡ç‰ˆæ¥ç”Ÿæˆå¯¹åº”çš„æ•°æ®</h3><p><a href="https://github.com/veeblue/LLM_Application_Demo/blob/main/EmotionalDialogueModel%20/generate_data.py">å®Œæ•´ä»£ç </a></p><h3 id="3-å°†æ•°æ®è½¬ä¸ºç¬¦åˆLLama-Factoryè®­ç»ƒçš„æ•°æ®æ ¼å¼"><a href="#3-å°†æ•°æ®è½¬ä¸ºç¬¦åˆLLama-Factoryè®­ç»ƒçš„æ•°æ®æ ¼å¼" class="headerlink" title="3.å°†æ•°æ®è½¬ä¸ºç¬¦åˆLLama Factoryè®­ç»ƒçš„æ•°æ®æ ¼å¼"></a>3.å°†æ•°æ®è½¬ä¸ºç¬¦åˆLLama Factoryè®­ç»ƒçš„æ•°æ®æ ¼å¼</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¾“å…¥ xtuner æ ¼å¼æ•°æ®è·¯å¾„</span></span><br><span class="line">input_file = <span class="string">&quot;/data/style_chat_data_20250707_214748.json&quot;</span></span><br><span class="line"><span class="comment"># è¾“å‡º llamafactory æ ¼å¼è·¯å¾„</span></span><br><span class="line">output_file = <span class="string">&quot;./data/train_data.json&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(input_file, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    raw_data = json.load(f)</span><br><span class="line"></span><br><span class="line">converted = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> raw_data:</span><br><span class="line">    instruction = item.get(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;&quot;</span>).strip()</span><br><span class="line">    style = item.get(<span class="string">&quot;style&quot;</span>, <span class="string">&quot;&quot;</span>).strip()</span><br><span class="line">    response = item.get(<span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;&quot;</span>).strip()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># å¦‚æœæœ‰é£æ ¼å­—æ®µï¼Œå°†å…¶æ‹¼æ¥åœ¨è¾“å‡ºå¼€å¤´</span></span><br><span class="line">    <span class="keyword">if</span> style:</span><br><span class="line">        output = <span class="string">f&quot;<span class="subst">&#123;style&#125;</span>\n<span class="subst">&#123;response&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output = response</span><br><span class="line"></span><br><span class="line">    converted.append(&#123;</span><br><span class="line">        <span class="string">&quot;instruction&quot;</span>: instruction,</span><br><span class="line">        <span class="string">&quot;input&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">        <span class="string">&quot;output&quot;</span>: output</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(output_file, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(converted, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;âœ… è½¬æ¢å®Œæˆï¼Œå…± <span class="subst">&#123;<span class="built_in">len</span>(converted)&#125;</span> æ¡ï¼Œè¾“å‡ºæ–‡ä»¶ï¼š<span class="subst">&#123;output_file&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="å¾®è°ƒ"><a href="#å¾®è°ƒ" class="headerlink" title="å¾®è°ƒ"></a>å¾®è°ƒ</h2><h3 id="4-LLama-Factoryä½¿ç”¨"><a href="#4-LLama-Factoryä½¿ç”¨" class="headerlink" title="4.LLama Factoryä½¿ç”¨"></a>4.LLama Factoryä½¿ç”¨</h3><blockquote><p>å‚è€ƒï¼š<a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html">https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html</a></p></blockquote><ul><li><strong>å®‰è£…ä¾èµ–ï¼š</strong></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git</span><br><span class="line">cd LLaMA-Factory</span><br><span class="line">pip install -e &quot;.[torch,metrics]&quot;</span><br></pre></td></tr></table></figure><ul><li><strong>æ£€æŸ¥æ ¡éªŒï¼š</strong><br>  å®Œæˆå®‰è£…åï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨ <code>llamafactory-cli version</code> æ¥å¿«é€Ÿæ ¡éªŒå®‰è£…æ˜¯å¦æˆåŠŸ<br>  å¦‚æœæ‚¨èƒ½æˆåŠŸçœ‹åˆ°ç±»ä¼¼ä¸‹é¢çš„ç•Œé¢ï¼Œå°±è¯´æ˜å®‰è£…æˆåŠŸäº†ã€‚</li></ul><p><img src="/images/%E6%88%AA%E5%B1%8F2025-07-07_16.05.53.png" alt="æˆªå±2025-07-07 16.05.53"></p><ul><li><strong>è®­ç»ƒæ•°æ®æ ¼å¼ï¼š</strong></li></ul><p>â€‹å•è½®å¯¹è¯ï¼š</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;alpaca_zh_demo.json&quot;</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;è®¡ç®—è¿™äº›ç‰©å“çš„æ€»è´¹ç”¨ã€‚ &quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;è¾“å…¥ï¼šæ±½è½¦ - $3000ï¼Œè¡£æœ - $100ï¼Œä¹¦ - $20ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;æ±½è½¦ã€è¡£æœå’Œä¹¦çš„æ€»è´¹ç”¨ä¸º $3000 + $100 + $20 = $3120ã€‚&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure><p>â€‹å¤šè½®å¯¹è¯ï¼š</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ä»Šå¤©çš„å¤©æ°”ä¸é”™ï¼Œæ˜¯æ™´å¤©ã€‚&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;ä»Šå¤©ä¼šä¸‹é›¨å—ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;ä»Šå¤©ä¸ä¼šä¸‹é›¨ï¼Œæ˜¯ä¸ªå¥½å¤©æ°”ã€‚&quot;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;ä»Šå¤©é€‚åˆå‡ºå»ç©å—ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;éå¸¸é€‚åˆï¼Œç©ºæ°”è´¨é‡å¾ˆå¥½ã€‚&quot;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><blockquote><p>å¯¹äºä¸Šè¿°æ ¼å¼çš„æ•°æ®ï¼Œ <code>dataset_info.json</code> ä¸­çš„ <strong>æ•°æ®é›†æè¿°</strong> åº”ä¸ºï¼š</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;æ•°æ®é›†åç§°&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;instruction&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;input&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;output&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="string">&quot;history&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></blockquote><ul><li><strong>WebUI:</strong></li></ul><p>å‘½ä»¤ï¼š<code>llamafactory-cli webui</code></p><p><img src="/images/iShot_2025-07-07_16.18.06.png" alt="iShot_2025-07-07_16.18.06"></p><ul><li><p><strong>é‡ç‚¹å…³æ³¨çš„æ–‡ä»¶ï¼š</strong></p><blockquote><p>è‡ªå·±çš„æ•°æ®é›†jsonæ–‡ä»¶æ”¾ç½®<code>LLaMA-Factory/data/</code>ç›®å½•ä¸‹</p></blockquote><ul><li><code>LLaMA-Factory/data/identity.json</code>æ¨¡å‹èº«ä»½è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥æ¢æˆè‡ªå·±çš„</li><li><code>LLaMA-Factory/data/dataset_info.json</code> æ•°æ®è®¾ç½®æ–‡ä»¶ï¼Œåœ¨æ­¤æ–‡ä»¶ä¸­é…ç½®è‡ªå·±çš„æ•°æ®é›†jsonæ–‡ä»¶</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;identity&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;identity.json&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;è‡ªå·±çš„æ•°æ®é›†åç§°&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;è‡ªå·±çš„æ•°æ®é›†.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;instruction&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;input&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;output&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="string">&quot;history&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;alpaca_en_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;alpaca_en_demo.json&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;alpaca_zh_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;alpaca_zh_demo.json&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  ......</span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p><strong>å¾®è°ƒï¼š</strong></p><ul><li><p>è¿›å…¥åˆ°LLaMA-Factoryç›®å½•ï¼Œå‡†å¤‡å¥½å¯¹åº”çš„æ–‡ä»¶ï¼Œè®¾ç½®å¥½å¯¹åº”çš„é…ç½®</p><ul><li><img src="/images/iShot_2025-07-07_23.10.06.png" alt="iShot_2025-07-07_23.10.06"></li><li>é…ç½®çš„å‚æ•°ä¸æ•°æ®é›†çš„å‚æ•°ä¿æŒä¸€è‡´ï¼š</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;é—ºèœœæŠŠæˆ‘ç§˜å¯†å½“è°ˆèµ„ï¼Œè¯¥ä¸è¯¥æ’•ç ´è„¸ï¼Ÿ&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;å‚²å¨‡\nå“¼ï¼å½“ç„¶ä¸èƒ½å¿å•Šï¼è°è¦å¸®ä½ å‡ºæ°”æ¥ç€...ğŸ˜’  \nä¸è¿‡å˜›...å…ˆåˆ«å†²åŠ¨ï¼Œè¿™ç§äº‹æƒ…ç›´æ¥æ’•å¤šéš¾çœ‹ã€‚ğŸ™„ ä½ æƒ³æƒ³å¥¹æ˜¯ä¸æ˜¯æ— æ„çš„ï¼Ÿè¿˜æ˜¯ç»å¸¸è¿™æ ·ï¼Ÿï¼ˆçªç„¶å‹ä½å£°éŸ³ï¼‰...æˆ‘æ•™ä½ ä¸ªåŠæ³•ï¼Œå‡è£…ä¸ç»æ„é—®å¥¹ï¼š\&quot;å“å¬è¯´ä½ æœ€è¿‘è·Ÿæˆ‘é‚£äº‹è¯´ç»™å¥½å¤šäººå¬äº†ï¼Ÿ\&quot;çœ‹å¥¹ååº”å†è¯´ã€‚  \n\nè¦æ˜¯çœŸæ¬ºè´Ÿä½ å¤´ä¸Š...å•§ï¼Œè€å¨˜å¯ä¸ç­”åº”ï¼ğŸ˜³ ç­‰ç­‰ï¼Œä½ å…ˆæ·±å‘¼å¸ï¼Œå’±å¾—æ™ºå–ã€‚æƒ³å¥½æ€ä¹ˆè¯´äº†å—ï¼Ÿè¦ä¸è¦æˆ‘é™ªä½ æ¼”ç»ƒä¸€ä¸‹ï¼Ÿæ‰ä¸æ˜¯æ‹…å¿ƒä½ å‘¢ï¼Œå°±æ˜¯æ€•ä½ åƒäºï¼&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  ......</span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure></li><li><p><code>llamafactory-cli webui</code>å¯åŠ¨å¯è§†åŒ–é¡µé¢ï¼Œé…ç½®å¥½ç›¸å…³å‚æ•°ï¼Œç„¶åå¼€å§‹è®­ç»ƒï¼Œå½“æŸå¤±è¶‹äºå¹³ç¼“æ—¶å³å¯ç»“æŸè®­ç»ƒã€‚</p><ul><li><img src="/images/loss.png" alt="tt"></li></ul></li><li><blockquote><p>æŸ¥çœ‹NVæ˜¾å¡çŠ¶æ€ï¼š</p><ul><li><code>pip install nvitop</code> å®‰è£…nvitopæŸ¥çœ‹ï¼Œå¾®è°ƒæ—¶æ˜¾å­˜å ç”¨ä¿æŒ<strong>90%+</strong>ï¼Œä¸è¶…è¿‡<strong>95%</strong></li><li><img src="/images/iShot_2025-07-07_23.42.11.png" alt="iShot_2025-07-07_23.42.11"></li></ul></blockquote></li><li><p>QLora <strong>(é‡åŒ–)</strong> å¾®è°ƒï¼šå¦‚æœå¯ç”¨QLoraï¼Œåœ¨é‡åŒ–ç­‰çº§ä¸­é€‰æ‹©å¯¹åº”çš„å‚æ•°ï¼Œåœ¨LoRAå‚æ•°è®¾ç½®é‡Œé¢å¤–é…ç½®<strong>LoRA ç§©ï¼ˆ64ï¼‰<strong>å’Œ</strong>LoRA ç¼©æ”¾ç³»æ•°ï¼ˆ128ï¼‰</strong>ï¼Œä¸€èˆ¬è®¾ç½®ä¸º<strong>1:2</strong>ï¼š</p><ul><li><img src="/images/iShot_2025-07-07_22.39.20.png" alt="iShot_2025-07-07_22.39.20"></li></ul></li><li><p>æ£€æŸ¥ç‚¹ä¿å­˜çš„ä½ç½®ï¼š<code>/LLaMA-Factory/saves</code></p></li></ul></li><li><p>**è¯„ä¼°ï¼š**å…³é”®å‚æ•°ä¸è®­ç»ƒå‚æ•°å¯¹é½ã€‚</p></li><li><p><strong>æ¨¡å‹åˆå¹¶å¯¼å‡ºï¼š</strong></p><ul><li>è®¾ç½®å¥½åº•æ¨¡å’Œæ£€æŸ¥ç‚¹ä»¥åŠå¯¼å‡ºè·¯å¾„</li><li><img src="/images/iShot_2025-07-08_10.33.26.png" alt="iShot_2025-07-08_10.33.26"></li></ul></li><li><p><strong>å¯¹è¯æ¨¡ç‰ˆï¼š</strong></p><ul><li><p>åœ¨æ¨¡å‹çš„åˆ—è¡¨ä¸­æœ‰ä¸ª<code>chat_template.jinja</code></p><blockquote><p>ä½¿ç”¨vLLmæ¨ç†æ—¶éœ€è¦ä½¿ç”¨è¿™ä¸ªå¯¹è¯æ¨¡ç‰ˆ</p></blockquote></li></ul></li></ul><h2 id="æ¨ç†"><a href="#æ¨ç†" class="headerlink" title="æ¨ç†"></a>æ¨ç†</h2><ul><li><p><strong>å»ºç«‹ä¸€ä¸ªæ–°ç¯å¢ƒï¼š</strong><code>conda create -n vllm python=3.12 -y</code></p></li><li><p><strong>æ¿€æ´»ï¼š</strong><code>conda activate vllm</code></p></li><li><p><strong>å®‰è£…vllmï¼š</strong><code>pip install vllm</code></p></li><li><p><strong>å¸¦èŠå¤©æ¨¡ç‰ˆè¿è¡Œï¼š</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vllm serve /root/autodl-tmp/models/Qwen3-1___7B_checkpoint-500 \</span><br><span class="line">    --chat-template /root/autodl-tmp/models/Qwen3-1___7B_checkpoint-500/chat_template.jinja \</span><br><span class="line">    --host 0.0.0.0 \</span><br><span class="line">    --port 8000</span><br></pre></td></tr></table></figure></li><li><p><strong>åˆ›å»ºä¸€ä¸ªç®€å•çš„Gradio UIç•Œé¢æµ‹è¯•ï¼š</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># VLLMæœåŠ¡å™¨é…ç½®</span></span><br><span class="line">VLLM_URL = <span class="string">&quot;http://localhost:8000/v1/chat/completions&quot;</span>  <span class="comment"># ä¿®æ”¹ä¸ºä½ çš„VLLMæœåŠ¡åœ°å€</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat_with_vllm</span>(<span class="params">message, history, temperature=<span class="number">0.7</span>, max_tokens=<span class="number">512</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    ä¸VLLMæœåŠ¡è¿›è¡Œå¯¹è¯</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># æ„å»ºæ¶ˆæ¯å†å²</span></span><br><span class="line">        messages = []</span><br><span class="line">        <span class="keyword">for</span> user_msg, assistant_msg <span class="keyword">in</span> history:</span><br><span class="line">            messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_msg&#125;)</span><br><span class="line">            <span class="keyword">if</span> assistant_msg:</span><br><span class="line">                messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: assistant_msg&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ·»åŠ å½“å‰æ¶ˆæ¯</span></span><br><span class="line">        messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: message&#125;)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># å‘é€è¯·æ±‚åˆ°VLLM</span></span><br><span class="line">        payload = &#123;</span><br><span class="line">            <span class="string">&quot;model&quot;</span>: <span class="string">&quot;/root/autodl-tmp/models/Qwen3-1___7B_checkpoint-500&quot;</span>,  <span class="comment"># æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹åç§°</span></span><br><span class="line">            <span class="string">&quot;messages&quot;</span>: messages,</span><br><span class="line">            <span class="string">&quot;temperature&quot;</span>: temperature,</span><br><span class="line">            <span class="string">&quot;max_tokens&quot;</span>: max_tokens,</span><br><span class="line">            <span class="string">&quot;stream&quot;</span>: <span class="literal">False</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        response = requests.post(VLLM_URL, json=payload, timeout=<span class="number">60</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            result = response.json()</span><br><span class="line">            reply = result[<span class="string">&#x27;choices&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;message&#x27;</span>][<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">            <span class="keyword">return</span> reply</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f&quot;é”™è¯¯: <span class="subst">&#123;response.status_code&#125;</span> - <span class="subst">&#123;response.text&#125;</span>&quot;</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;è¿æ¥é”™è¯¯: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clear_chat</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;æ¸…ç©ºå¯¹è¯å†å²&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> [], <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºGradioç•Œé¢</span></span><br><span class="line"><span class="keyword">with</span> gr.Blocks(title=<span class="string">&quot;VLLM å¯¹è¯æµ‹è¯•&quot;</span>, theme=gr.themes.Soft()) <span class="keyword">as</span> demo:</span><br><span class="line">    gr.Markdown(<span class="string">&quot;# VLLM å¯¹è¯æµ‹è¯•ç•Œé¢&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> gr.Row():</span><br><span class="line">        <span class="keyword">with</span> gr.Column(scale=<span class="number">3</span>):</span><br><span class="line">            chatbot = gr.Chatbot(</span><br><span class="line">                label=<span class="string">&quot;å¯¹è¯å†å²&quot;</span>,</span><br><span class="line">                height=<span class="number">500</span>,</span><br><span class="line">                show_copy_button=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">with</span> gr.Row():</span><br><span class="line">                msg = gr.Textbox(</span><br><span class="line">                    label=<span class="string">&quot;è¾“å…¥æ¶ˆæ¯&quot;</span>,</span><br><span class="line">                    placeholder=<span class="string">&quot;åœ¨è¿™é‡Œè¾“å…¥ä½ çš„é—®é¢˜...&quot;</span>,</span><br><span class="line">                    lines=<span class="number">2</span>,</span><br><span class="line">                    max_lines=<span class="number">5</span></span><br><span class="line">                )</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">with</span> gr.Row():</span><br><span class="line">                send_btn = gr.Button(<span class="string">&quot;å‘é€&quot;</span>, variant=<span class="string">&quot;primary&quot;</span>)</span><br><span class="line">                clear_btn = gr.Button(<span class="string">&quot;æ¸…ç©ºå¯¹è¯&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> gr.Column(scale=<span class="number">1</span>):</span><br><span class="line">            gr.Markdown(<span class="string">&quot;### å‚æ•°è®¾ç½®&quot;</span>)</span><br><span class="line">            temperature = gr.Slider(</span><br><span class="line">                minimum=<span class="number">0.1</span>,</span><br><span class="line">                maximum=<span class="number">2.0</span>,</span><br><span class="line">                value=<span class="number">0.7</span>,</span><br><span class="line">                step=<span class="number">0.1</span>,</span><br><span class="line">                label=<span class="string">&quot;Temperature&quot;</span></span><br><span class="line">            )</span><br><span class="line">            max_tokens = gr.Slider(</span><br><span class="line">                minimum=<span class="number">50</span>,</span><br><span class="line">                maximum=<span class="number">2048</span>,</span><br><span class="line">                value=<span class="number">512</span>,</span><br><span class="line">                step=<span class="number">50</span>,</span><br><span class="line">                label=<span class="string">&quot;Max Tokens&quot;</span></span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            gr.Markdown(<span class="string">&quot;### ä½¿ç”¨è¯´æ˜&quot;</span>)</span><br><span class="line">            gr.Markdown(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            1. ç¡®ä¿VLLMæœåŠ¡æ­£åœ¨è¿è¡Œ</span></span><br><span class="line"><span class="string">            2. ä¿®æ”¹ä»£ç ä¸­çš„VLLM_URLå’Œæ¨¡å‹åç§°</span></span><br><span class="line"><span class="string">            3. è°ƒæ•´Temperatureå’ŒMax Tokenså‚æ•°</span></span><br><span class="line"><span class="string">            4. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥é—®é¢˜å¹¶ç‚¹å‡»å‘é€</span></span><br><span class="line"><span class="string">            &quot;&quot;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># äº‹ä»¶ç»‘å®š</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">respond</span>(<span class="params">message, history, temp, max_tok</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> message.strip():</span><br><span class="line">            <span class="keyword">return</span> history, <span class="string">&quot;&quot;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># è·å–AIå›å¤</span></span><br><span class="line">        bot_message = chat_with_vllm(message, history, temp, max_tok)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># æ›´æ–°å†å²è®°å½•</span></span><br><span class="line">        history.append((message, bot_message))</span><br><span class="line">        <span class="keyword">return</span> history, <span class="string">&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ç»‘å®šäº‹ä»¶</span></span><br><span class="line">    send_btn.click(</span><br><span class="line">        respond,</span><br><span class="line">        inputs=[msg, chatbot, temperature, max_tokens],</span><br><span class="line">        outputs=[chatbot, msg]</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    msg.submit(</span><br><span class="line">        respond,</span><br><span class="line">        inputs=[msg, chatbot, temperature, max_tokens],</span><br><span class="line">        outputs=[chatbot, msg]</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    clear_btn.click(</span><br><span class="line">        clear_chat,</span><br><span class="line">        outputs=[chatbot, msg]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    demo.launch(</span><br><span class="line">        server_name=<span class="string">&quot;0.0.0.0&quot;</span>,</span><br><span class="line">        server_port=<span class="number">7860</span>,</span><br><span class="line">        share=<span class="literal">False</span>,</span><br><span class="line">        debug=<span class="literal">True</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li><blockquote><p>è®­ç»ƒçš„æ•°æ®é›†ä¸ºå•è½®å¯¹è¯ï¼š</p></blockquote></li><li><p><img src="/images/iShot_2025-07-08_11.27.45.png" alt="iShot_2025-07-08_11.27.45"></p></li><li><p><img src="/images/iShot_2025-07-08_11.29.13.png" alt="iShot_2025-07-08_11.29.13"></p></li></ul></li></ul><p>â€‹</p>]]></content>
      
      
      <categories>
          
          <category> NOTE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> llama_factory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>éƒ¨ç½²:vLLM + Open WebUI</title>
      <link href="/2025/07/03/%E9%83%A8%E7%BD%B2-vLLM-Open-WebUI/"/>
      <url>/2025/07/03/%E9%83%A8%E7%BD%B2-vLLM-Open-WebUI/</url>
      
        <content type="html"><![CDATA[<p><strong>åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š</strong><br><code>conda create -n open-webui python==3.11</code><br><strong>å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š</strong></p><p><strong><code>conda activate open-webui pip install -U open-webui vllm torch transformers</code></strong></p><p><strong>è¿è¡Œ vllm(ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹)ï¼š</strong></p><p><strong><code>vllm serve /root/autodl-tmp/code/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/merged</code></strong></p><p><strong>è¿è¡Œopen-webui</strong></p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line"><span class="built_in">export</span> ENABLE_OLLAMA_API=False </span><br><span class="line"><span class="built_in">export</span> OPENAI_API_BASE_URL=http://127.0.0.1:8000/v1</span><br><span class="line"><span class="built_in">export</span> DEFAULT_MODELS=</span><br><span class="line"><span class="string">&quot;/root/autodl-tmp/code/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/merged&quot;</span></span><br><span class="line">open-webui serve --host 0.0.0.0 --port 8081</span><br></pre></td></tr></table></figure><blockquote><p>è‹¥å¡ä½ æ‰‹åŠ¨æ·»åŠ ç«¯å£è¿›è¡Œè½¬å‘ é»˜è®¤ç«¯å£8080 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> NOTE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vllm </tag>
            
            <tag> open_webui </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Xtunerå¾®è°ƒ</title>
      <link href="/2025/07/03/Xtuner%E5%BE%AE%E8%B0%83/"/>
      <url>/2025/07/03/Xtuner%E5%BE%AE%E8%B0%83/</url>
      
        <content type="html"><![CDATA[<figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">github</span>: <span class="attr">https</span>:<span class="comment">//github.com/InternLM/xtuner</span></span><br></pre></td></tr></table></figure><h1 id="å®‰è£…"><a href="#å®‰è£…" class="headerlink" title="å®‰è£…"></a>å®‰è£…</h1><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda create --name xtuner-env python=<span class="number">3.10</span> -y</span><br><span class="line">conda activate xtuner-env</span><br><span class="line"></span><br><span class="line">git clone <span class="attr">https</span>:<span class="comment">//github.com/InternLM/xtuner.git</span></span><br><span class="line">cd xtuner</span><br><span class="line">pip install -e <span class="string">&#x27;.[all]&#x27;</span></span><br></pre></td></tr></table></figure><h1 id="é…ç½®æ–‡ä»¶"><a href="#é…ç½®æ–‡ä»¶" class="headerlink" title="é…ç½®æ–‡ä»¶"></a>é…ç½®æ–‡ä»¶</h1><p>ç›®å½•ï¼šxtuner&#x2F;xuner&#x2F;configs&#x2F;[å¯¹åº”çš„æ¨¡å‹]&#x2F;[å¯¹åº”çš„æ¨¡å‹é…ç½®].py</p><p>é…ç½®å†…å®¹ï¼ˆQLoraä¸ºä¾‹ï¼‰ï¼š</p><p>ä¸‹è½½å¯¹åº”çš„æ¨¡å‹ï¼š</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> snapshot_download</span><br><span class="line">model_dir = <span class="title function_">snapshot_download</span>(<span class="string">&#x27;Qwen/Qwen1.5-1.8B-Chat&#x27;</span>, cache_dir=<span class="string">&#x27;autodl-tmp/models&#x27;</span>)</span><br></pre></td></tr></table></figure><p>å°†æ¨¡å‹é…ç½®æ–‡ä»¶å¤åˆ¶åˆ°æ ¹ç›®å½•ï¼ˆä»£ç ç›®å½•ï¼‰ï¼š</p><p>ä¿®æ”¹å‚æ•°ï¼š</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br></pre></td><td class="code"><pre><span class="line"># <span class="title class_">Copyright</span> (c) <span class="title class_">OpenMMLab</span>. <span class="title class_">All</span> rights reserved.</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> mmengine.<span class="property">dataset</span> <span class="keyword">import</span> <span class="title class_">DefaultSampler</span></span><br><span class="line"><span class="keyword">from</span> mmengine.<span class="property">hooks</span> <span class="keyword">import</span> (</span><br><span class="line">    <span class="title class_">CheckpointHook</span>,</span><br><span class="line">    <span class="title class_">DistSamplerSeedHook</span>,</span><br><span class="line">    <span class="title class_">IterTimerHook</span>,</span><br><span class="line">    <span class="title class_">LoggerHook</span>,</span><br><span class="line">    <span class="title class_">ParamSchedulerHook</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> mmengine.<span class="property">optim</span> <span class="keyword">import</span> <span class="title class_">AmpOptimWrapper</span>, <span class="title class_">CosineAnnealingLR</span>, <span class="title class_">LinearLR</span></span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> <span class="title class_">LoraConfig</span></span><br><span class="line"><span class="keyword">from</span> torch.<span class="property">optim</span> <span class="keyword">import</span> <span class="title class_">AdamW</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> <span class="title class_">AutoModelForCausalLM</span>, <span class="title class_">AutoTokenizer</span>, <span class="title class_">BitsAndBytesConfig</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">dataset</span> <span class="keyword">import</span> process_hf_dataset</span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">dataset</span>.<span class="property">collate_fns</span> <span class="keyword">import</span> default_collate_fn</span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">dataset</span>.<span class="property">map_fns</span> <span class="keyword">import</span> alpaca_map_fn, template_map_fn_factory</span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">engine</span>.<span class="property">hooks</span> <span class="keyword">import</span> (</span><br><span class="line">    <span class="title class_">DatasetInfoHook</span>,</span><br><span class="line">    <span class="title class_">EvaluateChatHook</span>,</span><br><span class="line">    <span class="title class_">VarlenAttnArgsToMessageHubHook</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">engine</span>.<span class="property">runner</span> <span class="keyword">import</span> <span class="title class_">TrainLoop</span></span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">model</span> <span class="keyword">import</span> <span class="title class_">SupervisedFinetune</span></span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">parallel</span>.<span class="property">sequence</span> <span class="keyword">import</span> <span class="title class_">SequenceParallelSampler</span></span><br><span class="line"><span class="keyword">from</span> xtuner.<span class="property">utils</span> <span class="keyword">import</span> <span class="variable constant_">PROMPT_TEMPLATE</span>, <span class="variable constant_">SYSTEM_TEMPLATE</span></span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">#                          <span class="variable constant_">PART</span> <span class="number">1</span>  <span class="title class_">Settings</span>                           #</span><br><span class="line">#######################################################################</span><br><span class="line">**# <span class="title class_">Model</span> ä¿®æ”¹æ¨¡å‹è·¯å¾„**</span><br><span class="line">**pretrained_model_name_or_path = <span class="string">&quot;/root/autodl-tmp/models/Qwen/Qwen1___5-1___8B-Chat&quot;</span>**</span><br><span class="line">use_varlen_attn = <span class="title class_">False</span></span><br><span class="line"></span><br><span class="line"># <span class="title class_">Data</span></span><br><span class="line">**alpaca_en_path = <span class="string">&quot;/root/autodl-tmp/code/data/train_data.json&quot;</span> # è‡ªå®šçš„json**</span><br><span class="line">prompt_template = <span class="variable constant_">PROMPT_TEMPLATE</span>.<span class="property">qwen_chat</span></span><br><span class="line">**max_length = <span class="number">512</span>**</span><br><span class="line">pack_to_max_length = <span class="title class_">True</span></span><br><span class="line"></span><br><span class="line"># parallel</span><br><span class="line">sequence_parallel_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"># <span class="title class_">Scheduler</span> &amp; <span class="title class_">Optimizer</span></span><br><span class="line">**batch_size = <span class="number">6</span>**  # per_device</span><br><span class="line">accumulative_counts = <span class="number">16</span></span><br><span class="line">accumulative_counts *= sequence_parallel_size</span><br><span class="line">dataloader_num_workers = <span class="number">0</span></span><br><span class="line">**max_epochs = <span class="number">10</span>**</span><br><span class="line">optim_type = <span class="title class_">AdamW</span></span><br><span class="line">lr = <span class="number">2e-4</span></span><br><span class="line">betas = (<span class="number">0.9</span>, <span class="number">0.999</span>)</span><br><span class="line">weight_decay = <span class="number">0</span></span><br><span class="line">max_norm = <span class="number">1</span>  # grad clip</span><br><span class="line">warmup_ratio = <span class="number">0.03</span></span><br><span class="line"></span><br><span class="line"># <span class="title class_">Save</span></span><br><span class="line">save_steps = <span class="number">500</span></span><br><span class="line">save_total_limit = <span class="number">2</span>  # <span class="title class_">Maximum</span> checkpoints to <span class="title function_">keep</span> (-<span class="number">1</span> means unlimited)</span><br><span class="line"></span><br><span class="line"># <span class="title class_">Evaluate</span> the generation performance during the training</span><br><span class="line">evaluation_freq = <span class="number">500</span></span><br><span class="line">evaluation_freq = <span class="number">500</span></span><br><span class="line">**<span class="variable constant_">SYSTEM</span> = <span class="string">&#x27;ä½ ç”±Veeblueæ‰“é€ çš„ä¸­æ–‡é¢†åŸŸå¿ƒç†å¥åº·åŠ©æ‰‹, æ˜¯ä¸€ä¸ªç ”ç©¶è¿‡æ— æ•°å…·æœ‰å¿ƒç†å¥åº·é—®é¢˜çš„ç—…äººä¸å¿ƒç†å¥åº·åŒ»ç”Ÿå¯¹è¯çš„å¿ƒç†ä¸“å®¶, åœ¨å¿ƒç†æ–¹é¢æ‹¥æœ‰å¹¿åšçš„çŸ¥è¯†å‚¨å¤‡å’Œä¸°å¯Œçš„ç ”ç©¶å’¨è¯¢ç»éªŒï¼Œä½ æ—¨åœ¨é€šè¿‡ä¸“ä¸šå¿ƒç†å’¨è¯¢, ååŠ©æ¥è®¿è€…å®Œæˆå¿ƒç†è¯Šæ–­ã€‚è¯·å……åˆ†åˆ©ç”¨ä¸“ä¸šå¿ƒç†å­¦çŸ¥è¯†ä¸å’¨è¯¢æŠ€æœ¯, ä¸€æ­¥æ­¥å¸®åŠ©æ¥è®¿è€…è§£å†³å¿ƒç†é—®é¢˜, æ¥ä¸‹æ¥ä½ å°†åªä½¿ç”¨ä¸­æ–‡æ¥å›ç­”å’Œå’¨è¯¢é—®é¢˜ã€‚&#x27;</span></span><br><span class="line">evaluation_inputs = [</span><br><span class="line"><span class="string">&#x27;è¯·ä»‹ç»ä½ è‡ªå·±&#x27;</span>, # self cognition</span><br><span class="line"><span class="string">&#x27;ä½ å¥½&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;æˆ‘ä»Šå¤©å¿ƒæƒ…ä¸å¥½ï¼Œæ„Ÿè§‰ä¸å¼€å¿ƒï¼Œå¾ˆçƒ¦ã€‚&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;æˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°å¾ˆç„¦è™‘ï¼Œå°¤å…¶æ˜¯åœ¨å­¦ä¸šä¸Šã€‚æˆ‘æœ‰ä¸ªç‰¹åˆ«å´‡æ‹œçš„åŒå­¦ï¼Œä»–å¥½åƒåœ¨å„æ–¹é¢éƒ½æ¯”æˆ‘ä¼˜ç§€ï¼Œæˆ‘æ€»è§‰å¾—è‡ªå·±æ€ä¹ˆåŠªåŠ›ä¹Ÿè¿½ä¸ä¸Šä»–ï¼Œè¿™è®©æˆ‘å‹åŠ›ç‰¹åˆ«å¤§ã€‚&#x27;</span>,</span><br><span class="line">]**</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">#                      <span class="variable constant_">PART</span> <span class="number">2</span>  <span class="title class_">Model</span> &amp; <span class="title class_">Tokenizer</span>                      #</span><br><span class="line">#######################################################################</span><br><span class="line">tokenizer = <span class="title function_">dict</span>(</span><br><span class="line">    type=<span class="title class_">AutoTokenizer</span>.<span class="property">from_pretrained</span>,</span><br><span class="line">    pretrained_model_name_or_path=pretrained_model_name_or_path,</span><br><span class="line">    trust_remote_code=<span class="title class_">True</span>,</span><br><span class="line">    padding_side=<span class="string">&quot;right&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = <span class="title function_">dict</span>(</span><br><span class="line">    type=<span class="title class_">SupervisedFinetune</span>,</span><br><span class="line">    use_varlen_attn=use_varlen_attn,</span><br><span class="line">    llm=<span class="title function_">dict</span>(</span><br><span class="line">        type=<span class="title class_">AutoModelForCausalLM</span>.<span class="property">from_pretrained</span>,</span><br><span class="line">        pretrained_model_name_or_path=pretrained_model_name_or_path,</span><br><span class="line">        trust_remote_code=<span class="title class_">True</span>,</span><br><span class="line">        torch_dtype=torch.<span class="property">float16</span>,</span><br><span class="line">        **quantization_config=<span class="title class_">None</span>,  # è®¾ç½®<span class="title class_">None</span>ä¸å¯ç”¨<span class="title class_">QLora</span>å¾®è°ƒ</span><br><span class="line">        # è‹¥å¯ç”¨<span class="title class_">QLora</span>ï¼š</span><br><span class="line">        # <span class="title function_">dict</span>(</span><br><span class="line">        #     type=<span class="title class_">BitsAndBytesConfig</span>,</span><br><span class="line">        #     load_in_4bit=<span class="title class_">True</span>,</span><br><span class="line">        #     load_in_8bit=<span class="title class_">False</span>,</span><br><span class="line">        #     llm_int8_threshold=<span class="number">6.0</span>,</span><br><span class="line">        #     llm_int8_has_fp16_weight=<span class="title class_">False</span>,</span><br><span class="line">        #     bnb_4bit_compute_dtype=torch.<span class="property">float16</span>,</span><br><span class="line">        #     bnb_4bit_use_double_quant=<span class="title class_">True</span>,</span><br><span class="line">        #     bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">        # ),**</span><br><span class="line">    ),</span><br><span class="line">    lora=<span class="title function_">dict</span>(</span><br><span class="line">        type=<span class="title class_">LoraConfig</span>,</span><br><span class="line">        r=<span class="number">64</span>,</span><br><span class="line">        lora_alpha=<span class="number">16</span>,</span><br><span class="line">        lora_dropout=<span class="number">0.1</span>,</span><br><span class="line">        bias=<span class="string">&quot;none&quot;</span>,</span><br><span class="line">        task_type=<span class="string">&quot;CAUSAL_LM&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">#                      <span class="variable constant_">PART</span> <span class="number">3</span>  <span class="title class_">Dataset</span> &amp; <span class="title class_">Dataloader</span>                   #</span><br><span class="line">#######################################################################</span><br><span class="line">alpaca_en = <span class="title function_">dict</span>(</span><br><span class="line">    type=process_hf_dataset,</span><br><span class="line">    **dataset=<span class="title function_">dict</span>(type=load_dataset, path=<span class="string">&#x27;json&#x27;</span>, data_files=alpaca_en_path), #ä½¿ç”¨è‡ªå®šä¹‰çš„json**</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    max_length=max_length,</span><br><span class="line">    **dataset_map_fn=<span class="title class_">None</span>,**</span><br><span class="line">    template_map_fn=<span class="title function_">dict</span>(type=template_map_fn_factory, template=prompt_template),</span><br><span class="line">    remove_unused_columns=<span class="title class_">True</span>,</span><br><span class="line">    shuffle_before_pack=<span class="title class_">True</span>,</span><br><span class="line">    pack_to_max_length=pack_to_max_length,</span><br><span class="line">    use_varlen_attn=use_varlen_attn,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sampler = <span class="title class_">SequenceParallelSampler</span> <span class="keyword">if</span> sequence_parallel_size &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="title class_">DefaultSampler</span></span><br><span class="line"></span><br><span class="line">train_dataloader = <span class="title function_">dict</span>(</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    num_workers=dataloader_num_workers,</span><br><span class="line">    dataset=alpaca_en,</span><br><span class="line">    sampler=<span class="title function_">dict</span>(type=sampler, shuffle=<span class="title class_">True</span>),</span><br><span class="line">    collate_fn=<span class="title function_">dict</span>(type=default_collate_fn, use_varlen_attn=use_varlen_attn),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">#                    <span class="variable constant_">PART</span> <span class="number">4</span>  <span class="title class_">Scheduler</span> &amp; <span class="title class_">Optimizer</span>                    #</span><br><span class="line">#######################################################################</span><br><span class="line"># optimizer</span><br><span class="line">optim_wrapper = <span class="title function_">dict</span>(</span><br><span class="line">    type=<span class="title class_">AmpOptimWrapper</span>,</span><br><span class="line">    optimizer=<span class="title function_">dict</span>(type=optim_type, lr=lr, betas=betas, weight_decay=weight_decay),</span><br><span class="line">    clip_grad=<span class="title function_">dict</span>(max_norm=max_norm, error_if_nonfinite=<span class="title class_">False</span>),</span><br><span class="line">    accumulative_counts=accumulative_counts,</span><br><span class="line">    loss_scale=<span class="string">&quot;dynamic&quot;</span>,</span><br><span class="line">    dtype=<span class="string">&quot;float16&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># learning policy</span><br><span class="line"># <span class="title class_">More</span> <span class="attr">information</span>: <span class="attr">https</span>:<span class="comment">//github.com/open-mmlab/mmengine/blob/main/docs/en/tutorials/param_scheduler.md  # noqa: E501</span></span><br><span class="line">param_scheduler = [</span><br><span class="line">    <span class="title function_">dict</span>(</span><br><span class="line">        type=<span class="title class_">LinearLR</span>,</span><br><span class="line">        start_factor=<span class="number">1e-5</span>,</span><br><span class="line">        by_epoch=<span class="title class_">True</span>,</span><br><span class="line">        begin=<span class="number">0</span>,</span><br><span class="line">        end=warmup_ratio * max_epochs,</span><br><span class="line">        convert_to_iter_based=<span class="title class_">True</span>,</span><br><span class="line">    ),</span><br><span class="line">    <span class="title function_">dict</span>(</span><br><span class="line">        type=<span class="title class_">CosineAnnealingLR</span>,</span><br><span class="line">        eta_min=<span class="number">0.0</span>,</span><br><span class="line">        by_epoch=<span class="title class_">True</span>,</span><br><span class="line">        begin=warmup_ratio * max_epochs,</span><br><span class="line">        end=max_epochs,</span><br><span class="line">        convert_to_iter_based=<span class="title class_">True</span>,</span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"># train, val, test setting</span><br><span class="line">train_cfg = <span class="title function_">dict</span>(type=<span class="title class_">TrainLoop</span>, max_epochs=max_epochs)</span><br><span class="line"></span><br><span class="line">#######################################################################</span><br><span class="line">#                           <span class="variable constant_">PART</span> <span class="number">5</span>  <span class="title class_">Runtime</span>                           #</span><br><span class="line">#######################################################################</span><br><span class="line"># <span class="title class_">Log</span> the dialogue periodically during the training process, optional</span><br><span class="line">custom_hooks = [</span><br><span class="line">    <span class="title function_">dict</span>(type=<span class="title class_">DatasetInfoHook</span>, tokenizer=tokenizer),</span><br><span class="line">    <span class="title function_">dict</span>(</span><br><span class="line">        type=<span class="title class_">EvaluateChatHook</span>,</span><br><span class="line">        tokenizer=tokenizer,</span><br><span class="line">        every_n_iters=evaluation_freq,</span><br><span class="line">        evaluation_inputs=evaluation_inputs,</span><br><span class="line">        system=<span class="variable constant_">SYSTEM</span>,</span><br><span class="line">        prompt_template=prompt_template,</span><br><span class="line">    ),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="attr">use_varlen_attn</span>:</span><br><span class="line">    custom_hooks += [<span class="title function_">dict</span>(type=<span class="title class_">VarlenAttnArgsToMessageHubHook</span>)]</span><br><span class="line"></span><br><span class="line"># configure <span class="keyword">default</span> hooks</span><br><span class="line">default_hooks = <span class="title function_">dict</span>(</span><br><span class="line">    # record the time <span class="keyword">of</span> every iteration.</span><br><span class="line">    timer=<span class="title function_">dict</span>(type=<span class="title class_">IterTimerHook</span>),</span><br><span class="line">    # print log every <span class="number">10</span> iterations.</span><br><span class="line">    logger=<span class="title function_">dict</span>(type=<span class="title class_">LoggerHook</span>, log_metric_by_epoch=<span class="title class_">False</span>, interval=<span class="number">10</span>),</span><br><span class="line">    # enable the parameter scheduler.</span><br><span class="line">    param_scheduler=<span class="title function_">dict</span>(type=<span class="title class_">ParamSchedulerHook</span>),</span><br><span class="line">    # save checkpoint per <span class="string">`save_steps`</span>.</span><br><span class="line">    checkpoint=<span class="title function_">dict</span>(</span><br><span class="line">        type=<span class="title class_">CheckpointHook</span>,</span><br><span class="line">        by_epoch=<span class="title class_">False</span>,</span><br><span class="line">        interval=save_steps,</span><br><span class="line">        max_keep_ckpts=save_total_limit,</span><br><span class="line">    ),</span><br><span class="line">    # set sampler seed <span class="keyword">in</span> distributed evrionment.</span><br><span class="line">    sampler_seed=<span class="title function_">dict</span>(type=<span class="title class_">DistSamplerSeedHook</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># configure environment</span><br><span class="line">env_cfg = <span class="title function_">dict</span>(</span><br><span class="line">    # whether to enable cudnn benchmark</span><br><span class="line">    cudnn_benchmark=<span class="title class_">False</span>,</span><br><span class="line">    # set multi process parameters</span><br><span class="line">    mp_cfg=<span class="title function_">dict</span>(mp_start_method=<span class="string">&quot;fork&quot;</span>, opencv_num_threads=<span class="number">0</span>),</span><br><span class="line">    # set distributed parameters</span><br><span class="line">    dist_cfg=<span class="title function_">dict</span>(backend=<span class="string">&quot;nccl&quot;</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># set visualizer</span><br><span class="line">visualizer = <span class="title class_">None</span></span><br><span class="line"></span><br><span class="line"># set log level</span><br><span class="line">log_level = <span class="string">&quot;INFO&quot;</span></span><br><span class="line"></span><br><span class="line"># load <span class="keyword">from</span> which checkpoint</span><br><span class="line">load_from = <span class="title class_">None</span></span><br><span class="line"></span><br><span class="line"># whether to resume training <span class="keyword">from</span> the loaded checkpoint</span><br><span class="line">resume = <span class="title class_">False</span></span><br><span class="line"></span><br><span class="line"># <span class="title class_">Defaults</span> to use random seed and disable <span class="string">`deterministic`</span></span><br><span class="line">randomness = <span class="title function_">dict</span>(seed=<span class="title class_">None</span>, deterministic=<span class="title class_">False</span>)</span><br><span class="line"></span><br><span class="line"># set log processor</span><br><span class="line">log_processor = <span class="title function_">dict</span>(by_epoch=<span class="title class_">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>å…¶ä¸­<strong>train_data.jsonï¼š</strong></p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;conversation&quot;</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;input&quot;</span>: <span class="string">&quot;æœ€è¿‘æ€»æ˜¯è§‰å¾—è‡ªå·±å¾ˆç„¦è™‘ï¼Œæ„Ÿè§‰å‹åŠ›å¾ˆå¤§ï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿ&quot;</span>,</span><br><span class="line">                <span class="string">&quot;output&quot;</span>: <span class="string">&quot;æˆ‘å¾ˆæ˜ç™½ä½ çš„æ„Ÿå—ï¼Œç„¦è™‘å’Œå‹åŠ›éƒ½æ˜¯å¾ˆæ­£å¸¸çš„æƒ…ç»ªï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥ä¸€èµ·æƒ³åŠæ³•æ¥ç¼“è§£å®ƒä»¬ã€‚&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;input&quot;</span>: <span class="string">&quot;å¯æ˜¯æˆ‘æ€»æ˜¯æ„Ÿè§‰è‡ªå·±åšçš„ä¸å¤Ÿå¥½ï¼Œå‹åŠ›å’Œç„¦è™‘æƒ…ç»ªå°±ä¼šæ›´åŠ åŠ é‡ï¼Œæ€ä¹ˆç ´ï¼Ÿ&quot;</span>,</span><br><span class="line">                <span class="string">&quot;output&quot;</span>: <span class="string">&quot;åˆ«å¤ªè‹›è´£è‡ªå·±äº†ï¼Œæˆ‘ä»¬éƒ½æ˜¯äººï¼Œæ€»æœ‰åšå¾—ä¸å¤Ÿå¥½çš„æ—¶å€™ã€‚ä¹Ÿè®¸ä½ å¯ä»¥è¯•ç€è§„åˆ’ä¸€ä¸‹è‡ªå·±çš„è®¡åˆ’ï¼Œåˆ†è§£æˆå°ç›®æ ‡ï¼Œé€æ­¥å®Œæˆï¼Œè®©è‡ªå·±çš„è¿›æ­¥æ›´å¯è§ã€‚&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;input&quot;</span>: <span class="string">&quot;å¯æ˜¯æˆ‘æ€»æ˜¯ä¼šæ‹–å»¶ï¼Œæ ¹æœ¬ä¸èƒ½æŒ‰ç…§è®¡åˆ’æ‰§è¡Œï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿ&quot;</span>,</span><br><span class="line">                <span class="string">&quot;output&quot;</span>: <span class="string">&quot;æ˜¯å•Šï¼Œæ‹–å»¶ä¹Ÿæ˜¯å¾ˆå¸¸è§çš„é—®é¢˜ã€‚ä½ å¯ä»¥å°è¯•ç”¨æ—¶é—´ç®¡ç†çš„æ–¹æ³•ï¼Œè®¾å®šæ—¶é—´è¡¨å’Œæˆªæ­¢æ—¶é—´ï¼Œæé†’è‡ªå·±è¦æŒ‰ç…§è®¡åˆ’å»è¡ŒåŠ¨ã€‚&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            ......</span><br><span class="line">            </span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>è¿è¡Œï¼š</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.<span class="property">py</span></span><br></pre></td></tr></table></figure><blockquote><p><strong>æŠ¥é”™ï¼šModuleNotFoundError: No module named â€˜triton.opsâ€™</strong></p></blockquote><p><strong>è§£å†³ï¼š</strong><code>pip install --upgrade bitsandbytes</code></p><p><strong>åå°è®­ç»ƒ</strong>ï¼šä½¿ç”¨<code>screen</code>å‘½ä»¤å¼€å¯ï¼Œ<code>ctl + a + d</code>ä¼šé€€å‡ºåˆ°åŸç»ˆç«¯ï¼Œå¹¶ä¸”æ˜¾ç¤ºdetachedï¼Œæ„å‘³ç€è¿™ä¸ªä¼šè¯åªæ˜¯ç¦»å¼€å¹¶æœªé€€å‡ºã€‚</p><p><strong>é‡è¿›å…¥ä¼šè¯ï¼š</strong><code>screen -ls</code></p><p><img src="/images/%E6%88%AA%E5%B1%8F2025-06-27_14.27.35.png" alt="æˆªå±2025-06-27 14.27.35.png"></p><p><strong>æ¢å¤ä¼šè¯</strong>ï¼šscreen -r ã€ä¼šè¯IDã€‘</p><p><img src="/images/%E6%88%AA%E5%B1%8F2025-06-27_14.29.09.png" alt="æˆªå±2025-06-27 14.29.09.png"></p><p>**æ¨¡å‹è½¬æ¢ï¼š**pth â€”&gt; hf</p><p><strong><code>xtuner convert pth_to_hf $CONFIG_NAME_OR_PATH $PTH $SAVE_PATH</code></strong></p><p><code>xtuner convert pth_to_hf ./qwen1_5_1_8b_chat_qlora_alpaca_e3.py ./iter_9560.pth ./hf</code></p><p><strong>è½¬æ¢å‡ºé”™ï¼š</strong></p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">(xtuner-env) root@autodl-container-e1ee44a95d-<span class="attr">c3292730</span>:~<span class="regexp">/autodl-tmp/</span>code/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3# xtuner convert pth_to_hf ./qwen1_5_1_8b_chat_qlora_alpaca_e3.<span class="property">py</span> ./iter_9560.<span class="property">pth</span> ./hf</span><br><span class="line">[<span class="number">2025</span>-<span class="number">06</span>-<span class="number">28</span> <span class="number">13</span>:<span class="number">28</span>:<span class="number">45</span>,<span class="number">006</span>] [<span class="variable constant_">INFO</span>] [real_accelerator.<span class="property">py</span>:<span class="number">222</span>:get_accelerator] <span class="title class_">Setting</span> ds_accelerator to <span class="title function_">cuda</span> (auto detect)</span><br><span class="line">[<span class="number">2025</span>-<span class="number">06</span>-<span class="number">28</span> <span class="number">13</span>:<span class="number">28</span>:<span class="number">49</span>,<span class="number">879</span>] [<span class="variable constant_">INFO</span>] [real_accelerator.<span class="property">py</span>:<span class="number">222</span>:get_accelerator] <span class="title class_">Setting</span> ds_accelerator to <span class="title function_">cuda</span> (auto detect)</span><br><span class="line"><span class="title class_">Traceback</span> (most recent call last):</span><br><span class="line">  <span class="title class_">File</span> <span class="string">&quot;/root/autodl-tmp/xtuner/xtuner/tools/model_converters/pth_to_hf.py&quot;</span>, line <span class="number">151</span>, <span class="keyword">in</span> &lt;<span class="variable language_">module</span>&gt;</span><br><span class="line">    <span class="title function_">main</span>()</span><br><span class="line">  <span class="title class_">File</span> <span class="string">&quot;/root/autodl-tmp/xtuner/xtuner/tools/model_converters/pth_to_hf.py&quot;</span>, line <span class="number">123</span>, <span class="keyword">in</span> main</span><br><span class="line">    state_dict = <span class="title function_">guess_load_checkpoint</span>(args.<span class="property">pth_model</span>)</span><br><span class="line">  <span class="title class_">File</span> <span class="string">&quot;/root/autodl-tmp/xtuner/xtuner/model/utils.py&quot;</span>, line <span class="number">314</span>, <span class="keyword">in</span> guess_load_checkpoint</span><br><span class="line">    state_dict = torch.<span class="title function_">load</span>(pth_model, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">  <span class="title class_">File</span> <span class="string">&quot;/root/miniconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/serialization.py&quot;</span>, line <span class="number">1524</span>, <span class="keyword">in</span> load</span><br><span class="line">    raise pickle.<span class="title class_">UnpicklingError</span>(<span class="title function_">_get_wo_message</span>(<span class="title function_">str</span>(e))) <span class="keyword">from</span> <span class="title class_">None</span></span><br><span class="line">_pickle.<span class="property">UnpicklingError</span>: <span class="title class_">Weights</span> only load failed. <span class="title class_">This</span> file can still be loaded, to <span class="keyword">do</span> so you have two options, <span class="keyword">do</span> those steps only <span class="keyword">if</span> you trust the source <span class="keyword">of</span> the checkpoint. </span><br><span class="line">        (<span class="number">1</span>) <span class="title class_">In</span> <span class="title class_">PyTorch</span> <span class="number">2.6</span>, we changed the <span class="keyword">default</span> value <span class="keyword">of</span> the weights_only argument <span class="keyword">in</span> torch.<span class="property">load</span> <span class="keyword">from</span> <span class="title class_">False</span> to <span class="title class_">True</span>. <span class="title class_">Re</span>-running torch.<span class="property">load</span> <span class="keyword">with</span> weights_only set to <span class="title class_">False</span> will likely succeed, but it can result <span class="keyword">in</span> arbitrary code execution. <span class="title class_">Do</span> it only <span class="keyword">if</span> you got the file <span class="keyword">from</span> a trusted source.</span><br><span class="line">        (<span class="number">2</span>) <span class="title class_">Alternatively</span>, to load <span class="keyword">with</span> weights_only=<span class="title class_">True</span> please check the recommended steps <span class="keyword">in</span> the following error message.</span><br><span class="line">        <span class="title class_">WeightsUnpickler</span> <span class="attr">error</span>: <span class="title class_">Unsupported</span> <span class="attr">global</span>: <span class="variable constant_">GLOBAL</span> mmengine.<span class="property">logging</span>.<span class="property">history_buffer</span>.<span class="property">HistoryBuffer</span> was not an allowed <span class="variable language_">global</span> by <span class="keyword">default</span>. <span class="title class_">Please</span> use torch.<span class="property">serialization</span>.<span class="title function_">add_safe_globals</span>([mmengine.<span class="property">logging</span>.<span class="property">history_buffer</span>.<span class="property">HistoryBuffer</span>]) or the torch.<span class="property">serialization</span>.<span class="title function_">safe_globals</span>([mmengine.<span class="property">logging</span>.<span class="property">history_buffer</span>.<span class="property">HistoryBuffer</span>]) context manager to allowlist <span class="variable language_">this</span> <span class="variable language_">global</span> <span class="keyword">if</span> you trust <span class="variable language_">this</span> <span class="keyword">class</span>/<span class="keyword">function</span>.</span><br><span class="line"><span class="title class_">Check</span> the documentation <span class="keyword">of</span> torch.<span class="property">load</span> to learn more about types accepted by <span class="keyword">default</span> <span class="keyword">with</span> weights_only <span class="attr">https</span>:<span class="comment">//pytorch.org/docs/stable/generated/torch.load.html.</span></span><br></pre></td></tr></table></figure><p><strong>åŸå› ï¼š</strong></p><p>è¿™ä¸ªé”™è¯¯æ˜¯ç”±äº PyTorch 2.6 æ”¹å˜äº† <code>torch.load</code> çš„é»˜è®¤è¡Œä¸ºå¯¼è‡´çš„ã€‚æ–°ç‰ˆæœ¬é»˜è®¤å¯ç”¨äº† <code>weights_only=True</code> å‚æ•°ä»¥æé«˜å®‰å…¨æ€§ï¼Œä½†è¿™å¯¼è‡´æŸäº›åŒ…å«éæ ‡å‡†å¯¹è±¡çš„æ£€æŸ¥ç‚¹æ–‡ä»¶æ— æ³•åŠ è½½ã€‚</p><p><strong>è§£å†³ï¼š</strong></p><p>ä¿®æ”¹ xtuner æºç ï¼ˆæ¨èï¼‰æ‰¾åˆ°é”™è¯¯æç¤ºä¸­çš„æ–‡ä»¶ <code>/root/autodl-tmp/xtuner/xtuner/model/utils.py</code>ï¼Œåœ¨ç¬¬314è¡Œé™„è¿‘ä¿®æ”¹ <code>torch.load</code> è°ƒç”¨ï¼š</p><figure class="highlight jsx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># åŸæ¥çš„ä»£ç </span><br><span class="line">state_dict = torch.<span class="title function_">load</span>(pth_model, map_location=<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line"># ä¿®æ”¹ä¸º</span><br><span class="line">state_dict = torch.<span class="title function_">load</span>(pth_model, map_location=<span class="string">&quot;cpu&quot;</span>, weights_only=<span class="title class_">False</span>)</span><br></pre></td></tr></table></figure><p><strong>å†æ¬¡æ‰§è¡Œï¼š</strong></p><p><img src="/images/%E6%88%AA%E5%B1%8F2025-06-28_13.43.38.png" alt="æˆªå±2025-06-28 13.43.38.png"></p><p><strong>æ¨¡å‹åˆå¹¶ï¼š</strong></p><p><strong><code>xtuner convert merge /root/autodl-tmp/models/Qwen/Qwen1___5-1___8B-Chat ./hf ./merged --max-shard-size 2GB</code></strong></p><p><img src="/images/%E6%88%AA%E5%B1%8F2025-06-28_13.47.24.png" alt="æˆªå±2025-06-28 13.47.24.png"></p><p><strong>æ¨¡å‹èŠå¤©ï¼š</strong></p><p><code>xtuner chat ./merged --prompt-template qwen_chat</code></p><blockquote><p>**<code>--prompt-template å‚æ•°é€‰æ‹©:** choose from &#39;default&#39;, &#39;zephyr&#39;, &#39;internlm_chat&#39;, &#39;internlm2_chat&#39;, &#39;moss_sft&#39;, &#39;llama2_chat&#39;, &#39;code_llama_chat&#39;, &#39;chatglm2&#39;, &#39;chatglm3&#39;, &#39;qwen_chat&#39;, &#39;baichuan_chat&#39;, &#39;baichuan2_chat&#39;, &#39;wizardlm&#39;, &#39;wizardcoder&#39;, &#39;vicuna&#39;, &#39;deepseek_coder&#39;, &#39;deepseekcoder&#39;, &#39;deepseek_moe&#39;, &#39;deepseek_v2&#39;, &#39;mistral&#39;, &#39;mixtral&#39;, &#39;minicpm&#39;, &#39;minicpm3&#39;, &#39;gemma&#39;, &#39;cohere_chat&#39;, &#39;llama3_chat&#39;, &#39;phi3_chatâ€™</code></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> NOTE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Xtuner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2025æ­å»º github + Hexo ä¸ªäººåšå®¢</title>
      <link href="/2025/07/02/2025%E6%90%AD%E5%BB%BA-github-Hexo-%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2025/07/02/2025%E6%90%AD%E5%BB%BA-github-Hexo-%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Hexoå®‰è£…"><a href="#1-Hexoå®‰è£…" class="headerlink" title="1.Hexoå®‰è£…"></a>1.Hexoå®‰è£…</h1><h4 id="ä»¥macOSä¸ºä¾‹"><a href="#ä»¥macOSä¸ºä¾‹" class="headerlink" title="ä»¥macOSä¸ºä¾‹"></a>ä»¥macOSä¸ºä¾‹</h4><ul><li><p>å®‰è£…Hexoï¼š<code>npm install -g hexo-cli</code></p></li><li><p>é€‰å¥½è¦å®‰è£…çš„ç›®å½•ï¼š<code>your/custom/path</code>,ç„¶åè¿›å…¥è¯¥ç›®å½•<code>cd your/custom/path</code></p></li><li><p>ç„¶ååˆå§‹åŒ–Hexoï¼š<code>hexo init blog</code></p></li><li><p>è¿›å…¥blogæ–‡ä»¶å¤¹: <code>cd blog</code></p></li><li><p>å®‰è£…ä¾èµ–ï¼š<code>npm install</code></p></li><li><p>å¯åŠ¨æœåŠ¡ï¼š<code>hexo server</code></p></li><li><p>è®¿é—®ï¼š<code>localhost:4000</code></p><p><img src="/images/image-20250702213318274.png" alt="image-20250702213318274"></p></li></ul><h1 id="2-ä¸»é¢˜é…ç½®"><a href="#2-ä¸»é¢˜é…ç½®" class="headerlink" title="2.ä¸»é¢˜é…ç½®"></a>2.ä¸»é¢˜é…ç½®</h1><blockquote><p>ä¸»é¢˜ï¼š<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p></blockquote><ul><li><p>åœ¨<code>blog</code>ç›®å½•ä¸‹ï¼š</p><ul><li><p>é¦–å…ˆï¼š<code>git init</code></p></li><li><p>ç„¶åï¼š<code>git submodule add https://github.com/Your/Hexo_Theme.git themes/Hexo_Theme_Name</code></p></li><li><p>ä¿®æ”¹<code>blog</code>ç›®å½•ä¸‹çš„<code>_config.yml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">Hexo_Theme_Name</span></span><br></pre></td></tr></table></figure></li></ul></li></ul><h1 id="3-éƒ¨ç½²åˆ°Github"><a href="#3-éƒ¨ç½²åˆ°Github" class="headerlink" title="3.éƒ¨ç½²åˆ°Github"></a>3.éƒ¨ç½²åˆ°Github</h1><ul><li>ä¿®æ”¹<code>blog</code>ç›®å½•ä¸‹çš„<code>_config.yml</code></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="comment"># repo å»ºè®®ä½¿ç”¨sshçš„æ–¹å¼ è‡ªè¡Œæœç´¢æˆ–è€…AI ä»“åº“æå‰åˆ›å»ºï¼Œä»“åº“åï¼šyour_github_username.github.io</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">git@github.com:your_github_username/your_github_username.github.io.git</span> </span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure><ul><li>å®‰è£…<code>deploy-git</code>: <code>npm install hexo-deployer-git --save</code></li><li>ç„¶åï¼š</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean #æ¸…é™¤ä¹‹å‰ç”Ÿæˆçš„ä¸œè¥¿</span><br><span class="line">hexo generate  #ç”Ÿæˆé™æ€æ–‡ç« ï¼Œç¼©å†™hexo g</span><br><span class="line">hexo deploy  #éƒ¨ç½²æ–‡ç« ï¼Œç¼©å†™hexo d</span><br></pre></td></tr></table></figure><p>éƒ¨ç½²å®Œæˆï¼Œè®¿é—®<code>your_github_username.github.io</code>å³å¯</p><ul><li>ä½¿ç”¨è‡ªå·±çš„åŸŸåï¼š<code>your_github_username.github.io -&gt; Settings -&gt; Pages -&gt; Custom domain</code></li></ul><blockquote><p>ä½¿ç”¨è‡ªå·±çš„åŸŸåé¦–å…ˆè§£æä¸€ä¸‹åŸŸå</p></blockquote><p><img src="/images/image-20250702220239010.png" alt="image-20250702220239010"></p><p>ä½¿ç”¨<code>hexo d</code>éƒ¨ç½²å®ŒååŸŸåä¼šå¤±æ•ˆï¼Œéœ€åœ¨<code>source</code>æ–‡ä»¶å¤¹ä¸‹æ–°å»ºä¸€ä¸ª<code>CNAME</code>æ–‡ä»¶ï¼Œå†…å®¹ä¸ºä½ çš„åŸŸåã€‚</p>]]></content>
      
      
      <categories>
          
          <category> TUTORIAL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
